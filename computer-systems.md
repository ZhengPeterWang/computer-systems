# CS 3410

本文档为CS 3410预习的笔记。这门课主要讨论计算机系统的构成，以及处理器、内存和并发是如何工作的。本课程架起了硬件和软件之间的桥梁。在国内，这门课的内容一般对应数字逻辑、计算机系统组成和汇编原理。

基础计算机可以看成由两个部分组成：内存(memory)和处理器(processor)。Central Processing Unit（CPU）就是现代电脑的处理器，而Random Access Memory(RAM)就是现代电脑的内存。处理器内部也有一些内部存储空间，称为寄存器(register），而处理器就相当于一个图灵机，不停地在不同状态间切换并修改寄存器的值，从而完成计算。内存则提供了远比处理器多的存储空间。两者是通过总线(bus)联系起来的。

为了与硬件交互，我们需要一种把内存和处理器抽象的平台，这样我们就能站在软件的角度理解硬件。这个平台叫指令集架构(Instruction Set Architecture)。

## 第1章 什么是电脑？电脑是怎么工作的？

目前的电脑主要有四种：个人电脑(PC)，服务器(server)，嵌入式微处理器（代表为单片机），和个人移动设备(PMD)。

### 1.1 电脑硬件简介

一个计算机主要由五个部分组成：**输入设备**（比如麦克风，键盘，鼠标），**输出设备**（比如音响，显示器，触摸屏），**内存，数据通路**(datapath)和**控制电路**，其中后两个经常并起来称为**处理器**。

#### 输入和输出设备

##### 图形显示

现代电脑是用二进制数字存储图像的。每个图像都被转成RGB格式表示的像素，每个像素都有三个字节，分别表示红色、绿色、蓝色。数以万计的像素形成了显示器。现代的显示器大都是液晶显示器，是利用液晶分子通电后会改变其偏振属性，从而改变偏振光光强的方法控制不同单色光强度，从而显示出不同颜色的。现代电脑控制显示图片的工具是帧缓冲器(frame buffer)，需要显示的位图(bit map)先存储到帧缓冲器，再按照刷新速率不断地把信息输送给显示器。

##### 触摸设备

现代移动设备大量采用了电容感应方案。绝缘体玻璃被人体（导体）触摸后会改变屏幕的电场进而改变其电容，从而能够让系统电路获得感应信息。当然键盘等传统的靠压力通断电路开关的触摸设备现仍然大量地在个人电脑中使用。

#### 处理器

处理器又称**中央处理单元**(CPU)，主要包括控制中心和数据通路。数据通路是完成全部计算的主要设备，而控制中心则负责解析需要完成哪些计算。处理器一般被安放在**芯片**(chip)上。我们将在之后的更多章节讨论处理器。

#### 内存

现代的内存主要以**随机存取内存**(RAM)为形式。内存主要有动态随机存储内存（DRAM，用来实现现代电脑主内存）和静态随机存储内存（SRAM，用来实现缓存,cache）。SRAM比DRAM更贵，内存容量更小，但更容易访问。以上的内存在2.3节中都有介绍。现代电脑运用了多种不同的内存形成一套内存等级，以便最大限度地利用所有资源，这在第2章和第4章中都有介绍。

SRAM、DRAM等都是临时内存。**临时内存**（volatile memory)主要是通过控制电路某部分电压是否大于阈值来实现的。一旦断电，所有临时内存就都会丢失。因此，还有另一种内存称为**永久存储**(nonvolatile storage)，把信息用物理的方式存起来。

永久存储主要有磁盘（magnetic disk，又称硬盘,hard disk, hard drive）和闪存(flash drive)。磁盘由盘片和磁头组成。盘片上布满了磁性物质。当我们向磁盘写信息时，磁头会去改变硬盘上某个位置的磁极。当我们向硬盘读信息时，磁头会去感应硬盘上某个位置的磁阻。为了读写盘片上的某个位置，磁头和盘片必须不停高速旋转以找到其对应的内存，这个过程会散发大量的热。磁盘内部还有一个微处理器，负责把读到的内容传递给数字电路。闪存则用电容存储信息。当闪存中的浮门带电时，闪存就拥有高电压，因此1就会被存储在这个晶体管。

内存全名 | 内存简称 | 存取时间 | 1GB存储的价格（2012）
-|-|-|-
静态随机存取内存 | SRAM | 10ns | $4k
动态随机存储内存 | DRAM | 50ns | $5 - $10
磁盘 | 硬盘 | 5 - 20 ms | $0.05 - $0.1
固态硬盘、闪存 | SSD | 0.1 ms | $1

我们将在之后的章节更多地讨论临时内存（第2章、第4章）和永久存储（操作系统第3章）。

#### 网络

网络是现代电脑必不可缺的部分。它能够允许信息交互、资源共享、远程控制。网络有两种规模：局域网(local area network, LAN)和广域网(wide area network, WAN)。现代局域网速可以达到1-40GB/s，而通过光纤宽带实现的广域网速业已达到1GB/s。以wifi标准和通信网络为基础的无线网现在成为全新的网络形式，目前一般的网速可以达到100MB/s。我们将在操作系统笔记的附录中简要介绍网络。

### 1.2 性能

电脑的性能可以用响应时间（延迟）和数据吞吐量描述。响应时间分为CPU时间和获得内存、IO等的时间，而CPU时间又分为系统CPU时间和用户CPU时间。我们之后主要讨论CPU时间，尤其是用户CPU时间。

决定性能的唯一标准是执行时间，但在不同的CPU上不同的程序执行时间有很大差别。一个程序的执行时间由指令个数、每指令执行的钟表圈数(CPI)、以及单位钟表圈数执行时间决定。一定要控制变量，才能够看出某个CPU执行某个任务的性能优劣。

为了提升性能，我们需要知道Amdahl定律，它强调，改变硬件或软件中某一部分的性能，并不能影响其他部分的性能，因此总性能提升受到提升性能是否经常被使用的影响。

### 1.3 指令集架构（电脑架构）

抽象性原理要求我们在研究更抽象内容时忽略具体实现细节，只需要把更具体的内容封装抽象为一个个模型即可。现代电脑最重要的一个抽象就是硬件与最低级软件之间的交互，这个交互模型称为**指令集架构**(Instruction Set Architecture)，简称**架构**(architecture)。这个抽象的架构是一套规则组成的要求，而具体的硬件应该*实现*这个要求。

在第3章中介绍处理器、第4章中介绍内存时，我们将更详细地讨论指令集架构。

## 第2章 电脑的电路基础

电脑是一个非常复杂的系统，但它的核心——处理器和内存——也不过是由大量三极管和电容组成的一个电路，本章主要讨论一个个电路元件是如何被层层聚合，层层抽象，从而构成计算的基本单位和存储的基本单位的，它们将会成为处理器和内存的基础。

### 2.1 逻辑门电路

电路中把开关串联和并联可以构成一系列门电路。而NPN型与PNP型三极管则可以通过控制基极电压大小来控制电路通断，因此它们的恰当组合也能形成门电路（这种恰当组合需要认真掌握，本笔记中以附录形式总结），从而数字电路的通断不再需要开关的机械控制。在具体实现中我们不去管门电路如何实现，而只是把它抽象成一个可以满足我们要求的电路元件，这是从电路到电脑的第一层抽象。

电路与布尔代数表达式和命题逻辑表达式之间有一一对应的关系。任何电路都有一个真值表，能用合取范式设计出来。这是门电路被广泛应用于逻辑设计的原因。

一个重要的问题是，给出一个真值表，能否造出一个满足该真值表的表达式，使其运用最少的逻辑运算符（最少的门电路器件）。Karnaugh Maps是一种可以寻找该表达式的方法。

在实际应用中，门电路常常会以确定的方式组织起来，形成组合逻辑电路块。以这些块作为单位可以更方便地组织更复杂的逻辑。这是在门电路之上的又一层抽象。比较器、选择器(multiplexor)、解码器(decoder)、编码器(encoder)是常见的组合电路块。

### 附录 布尔代数与命题逻辑

布尔代数是一种只有两个基本符号（0和1）和几个可以用真值表定义的二元算符组成的代数。命题逻辑是一种以命题为基本符号，以有关系的合取、析取等运算符连接，以真值表确定公式赋值的逻辑。事实上，命题逻辑赋值的规则就是布尔代数。

布尔代数（命题公式）有一些规范的表达形式，称为范式(canonical form)。范式分为合取范式（由最大项,maxterm,的积组成）和析取范式（由最小项,minterm，的和组成）。把任何命题逻辑表达式转成析取范式的方法是，写下命题逻辑表达式的（或者所需电路要求的）真值表，找到其中所有要求为1的行，把它们加起来就行了。

### 2.2 算术计算

以不同方式组合门电路块，可以实现算术计算，这就是电脑被称为计算机的原因。

通过门电路可以很方便地设计一个带进位功能的二进制全加法器，大致由6个门电路组成。加法器与加法器之间可以串联，这样理论上就可以设计出任意比特的加法器。用“2补法”构造每个正数的相反数可以构造与无符号整数兼容的有符号整数，这样就可以把加法运算的范围扩充到负数。减法就是加上相反数，因此减法也能用加法器串联组成，且能够与加法运算共用。8个比特的整数加法这样需要50个门电路左右就能完成了。注意一般比特的数目有限，因此大数字会导致计算越界，越界时可以通过一个选择器侦查结果符号是否正确，并抛出异常。

乘法、除法、甚至浮点数的计算，都能通过恰当的表示方式用比特和门电路的方式完成。当然门电路也能被用来比较数字大小。通过右移左移比特的方式还能完成乘方和开方。这样所有常用的算术计算都能用门电路完成了。

### 2.3 寄存器、内存

如何在一个瞬息万变的电路中存储什么信息呢？当然可以用电容是否带电的方式完成。但事实上只用门电路就可以实现存储信息。门电路可以组成多种多样的电器元件，这是在电脑组成中的第二层抽象。

SR锁存器(latch)是第一个可以存储一比特并改变其值的门电路。但SR锁存器中有一个态被禁止。D锁存器改进了SR锁存器，其中不再有禁止态，但D锁存器中存储的信号随外加信号的大小改变，也就是我们还是无法控制是修改这个比特还是存储这个比特。

为了实现周期性地决定是否存取某个内存，我们需要构造一个钟。电路中的钟就是周期信号，在本课程中我们使用正负边触发型钟，它是由电平的突然上升和下降来触发信号的。其他的还有电平触发型钟等。把两个D锁存器串联，再给它们接入相反的钟表信号，就造出了一个D触发器(flip-flop)。11个门电路就能造出一个D触发器。当C信号为稳定信号时，D触发器会存储内部的比特。当C信号为钟表的周期信号时，D触发器会在向下的那条棱时按照D信号更改内部存储的比特。

将大量D触发器并联，分享一个钟信号，就构成了一个寄存器(register)，例如32比特寄存器，这是第三层抽象。大量的寄存器又组成了一个叫寄存器文件(register file)的单元，通过与编码器(encoder)和解码器(decoder)的组合可以实现写内存，通过与选择器的组合可以实现读内存。在寄存器文件中存储非常快速，只经过几个门电路就能完成，但它要实现大内存存储很困难，因为造不出太大的选择器。

存储大内存需要对寄存器文件改进。可以通过三态缓冲器（tri-state buffer）控制同一时刻只有一个寄存器输出，且输出到一条所有寄存器共享的总线(bus)中去，这样就没必要造特别大的选择器了。利用这个思想可以造出静态随机存储内存(SRAM)，也就是常见电脑缓存使用的电路（见4.1节）大量触发器可以通过二维的方式组织，总线就是word line和bit line，每轮钟表周期只读或写一个内存，这又是一层抽象。SRAM使用比DRAM更少的门电路（6个三极管就能存储一个比特，相比于寄存器的多个D触发器），且可以scale，价格更便宜，但缺点是速度更慢（因为SRAM更大）。

更高效的存储还可以通过电容实现。理论上讲1个电容，加上一两个三极管，就能存储一个比特。这就是DRAM（也就是现代电脑主内存）实现的原理。DRAM价格便宜，更能scale，但DRAM的速度更慢（因为电容器电压调整的速度相比较门电路来慢得多），且长期使用会导致电容器上下极板的电荷积累，电压差无法达到可以辨别的要求，这时DRAM就会报废。

可以看出，门电路构成了实现寄存器、缓存和内存（即所有临时内存）的框架。需要注意的是，断电以后以上的门电路都将无法存储任何信息。因此永久性的存储（磁盘、闪存等）都不是用门电路存储的。

### 附录 硬件描述语言（HDL）

用画门电路或者电路块的形式组织电路太低效了。为了加快电路开发，人们开发了一批硬件描述语言，以描述数字设计中的大量顺序电路和逻辑电路。Verilog和VHDL是两种常用的硬件描述语言。

### 2.4 顺序逻辑、有限状态机

电子学中的电路常常概念性地分解为组合逻辑电路和顺序逻辑电路。组合逻辑电路完全可以由布尔代数的变量表达式描述。而顺序逻辑电路则还必须加上“内存”或状态来描述。从硬件角度，组合逻辑能够组成门电路和算术计算器，主要用来实现CPU中的算术逻辑单元（ALU），而顺序逻辑必须依靠内存（寄存器）才能实现。在2.3节中介绍的寄存器文件、SRAM、DRAM都是顺序逻辑电路的例子。

把寄存器文件与带输入输出的组合逻辑电路（已经在2.1节讨论过）结合起来，就构成了一套顺序逻辑电路，也就能实现有限状态机。这样，门电路就提供了一套极其丰富的计算工具。有限状态机的数学表达主要包括状态集、输入集、输出集和转移函数等，其中最核心的是转移函数，即在某状态下输入某值，应该转移到哪个态，输出哪个值。注意这里的有限状态机可以给出输出，与只有接受和不接受两态的有限自动机有不同之处。

有限状态机有两种，一种叫Moore机，它每一个转移的输出值只被当前状态决定，另一种叫Mealy机，它的输出值被输入值(input)和当前状态决定。Moore机和Mealy机可以相互转化。为了保存其存储的状态，有限状态机应该用一个寄存器来存储自己的状态，并通过一个接受输入和旧状态并产生输出和新状态的组合逻辑电路实现转移函数。

## 第3章 处理器

在拥有计算工具和寄存器、内存等之后，我们下一步将会考虑如何把它们组织起来实现指令。一个重要的经验是，指令（程序）也应该像数据一样存起来（存在内存中），只不过应该与数据分开存储，且程序执行时不会修改程序指令（哈佛架构）。这样我们就能拥有更灵活的执行指令的工具（如果不把指令分开存储，那么GOTO、递归、函数调用等等都将成为不可能）。本章中，我们以RISC-V指令集架构为例，阐述一套处理器的指令集架构是如何实现的，并讨论处理器的流水线优化。

### 3.1 汇编语言

汇编语言(assembly language)是处理器的语言，也是指令集架构的语言。x86，ARM等是常用的汇编语言。汇编语言的特点是语法非常简单，操作只有几种，硬件都比较容易实现，但用它执行高级编程不易。汇编语言的语句称为指令，每个指令都会指定对CPU中的某些寄存器做某些操作，或者读写某个地址存在某个寄存器中的内存，或者改变下一次需要执行的指令（不再是本条指令的下一条等）。RISC汇编语言是一种比较简单的汇编语言。

RISC类汇编语言的指令有加减逻辑左右移（包括add, sub, mul, div, or, xor, slt, sltu, sll, srl, sra等，其中加减常数称为中间值，如果想把常数设为大于2^12的数则需要使用lui先载入该数大于2^12的部分）、内存存取（包括lb, ld, lh, lw和sb, sd, sh, sw等）、控制执行语句（包括beq, bne, bge, blt, jal等）等。指令的词法主要有R型、I型、S型、SB型、U型等。

### 3.2 单圈处理器

RISC类汇编语言可以用RISC-V处理器实现。这个处理器分五部分：获取指令IF、解码指令ID、执行EX、内存读写MEM、回写寄存器WB。每个指令都会一次走过处理器的五个部分：第一步，从指令寄存器中读取要执行的指令。第二步，从数据寄存器文件中读取需要处理的数据。RISC-V使用了拥有32个32位寄存器的寄存器文件。（注意，内存一般把字节，即8个比特，作为最小的数据单元和一个块的大小，而RISC-V的寄存器则是32位寄存器，存储了4个字节）第三步，在ALU（算数逻辑单元）中执行指令。第四步，按照指令要求读写内存。第五步，把所有运算结果存到数据寄存器，同时按照指令要求增减指令计数器，为执行下一个指令做好准备。

注意处理器的电路可以分成数据通路(datapath)和控制电路(control)。控制电路解析汇编语言指令，通过门电路和选择器等控制数据的通断和计算，而数据通路则是从寄存器文件中取出的数据经过的电路。

算术与逻辑计算是比较简单的部分，只需要利用ALU就可以了。特别注意的是有中间值的算术计算，需要经过额外处理在其他地方传输中间值信号，还要注意中间值必须增位才能达到32位的寄存器存储值。

内存的获取和更改需要不停地读写SRAM或者DRAM或者其他。一般需要指明地址然后输入内存就可以了。与RISC-V的32位寄存器不同，一个内存单位一般只有8个比特（1个字节）。因此要把4个字节的寄存器数据存入内存时，就有存储顺序的问题。我们把最低位有效数字存储在最前（即4个字节中的第1个）的存储方式称为little endian，而最高位有效数字存储在最前的存储方式称为big endian。RISC-V和x86采用little endian，而MIPS和网络则采用big endian。

为了改变下一步执行的指令到某些其他指令，在寄存器获得某些信息后控制电路应该把跳步执行指令的运算结果发回一个加法器，去控制程序内存改变下一个调用的语句。RISC还支持按照某条件进行比较，确认下一步应执行哪一行指令，这样我们就设计完成了能实现RISC语言的RISC-V处理器的基本框架。

### 3.3 调用惯例

在汇编语言实现中，函数调用是值得特别注意的。为了让编译器正确编译，我们必须规定一套调用惯例（即寄存器使用惯例），以保证不同的函数能够以一套统一的规则使用RISC-V的32个寄存器。尽管RISC-V寄存器文件中32个寄存器都是通用寄存器，我们一般规定每个寄存器都有特定的用途。下表列出了本课程中RISC-V32个寄存器的调用惯例。编译器在把高级语言编译成RISC-V汇编语言时，必须遵守这个惯例，否则函数调用的指令切换将会带来混乱。

寄存器 | 别名 | 用途 | 备注
-|-|-|-
x0 | - | 返回0值 | 永远是0，不可写入
x1 | ra (return address) | 在函数调用正在进行时，存储返回时程序应跳到的地址 | 由调用者负责存储
x2 | sp (stack pointer) | 在函数调用时，存储内存中调用栈的第一个地址 | 由正在执行的函数负责存储。注意：调用栈的第一个地址是整个调用栈的最下端
x3 | gp (global pointer) | 存储内存中全局变量所在的第一个地址 | 全局变量
x4 | tp (thread pointer) | 线程寄存器 | 多线程使用，本课程不考虑
x5 - x7 | t0 - t2 | 临时寄存器 | 临时存储本函数所用的变量。在函数调用时不保证这些寄存器的值会被保存
x8 | s0/fp (frame pointer) | 帧寄存器 | 在函数调用时，存储内存中属于本函数调用栈的最后一个地址 | 由正在执行的函数负责存储。注意：调用栈最后一个地址是整个调用栈的最上端
x9 | s1 | 保存寄存器 | 调用者会把自己的一些局域变量存到这些寄存器里，被调用者在开始自己指令执行前必须把这些数据存到内存中，把sp下移，原sp与新sp中间存储这些寄存器，通过这种方式构建调用者函数的调用栈；在被调用者结束自己指令执行后，应把调用者的调用栈恢复到保存寄存器中，并把sp上移，消去调用者函数的调用栈
x10 - x11 | a0 - a1 | 函数参数和函数返回值 | 在执行jal调用函数前，调用者与被调用者约定在这些寄存器里存储函数调用参数；在调用者结束函数指令，执行jalr时，调用者与被调用者约定a0存储返回值
x12 - x17 | a2 - a7 | 函数参数 | 本调用惯例允许一个函数存储八个参数在寄存器里。多于八个参数应该存储到内存中
x18 - x27 | s2 - s11 | 保存寄存器 | 同s0-s1
x28 - x31 | t3 - t6 | 临时寄存器 | 同t0-t2

在用汇编语言实现函数调用时，编译器需要完成很多事情。调用开始前，编译器要把函数调用结束后返回的地址ra存在寄存器x1中；要在寄存器sp（x2）中维护内存中调用栈指针（地址），存储本函数的局域变量，方便递归；全局变量应该专门在寄存器中存放一指针gp，方便在内存中找到它们的存储位置；函数调用要传递参数，因此编译器应把需要传递的值移到a0-a7中去；函数调用要留下返回值，因此编译器应把返回值移到a0-a1中去；函数调用前要保存本函数的局域变量，因此调用前编译器要把局域变量存到“保存寄存器”中，被调用者在执行自己的指令前应该把这些保存寄存器的数据都存到内存（调用者的栈）中去（称为预处理prologue），在结束自己的指令后要把这些寄存器的值都恢复到保存寄存器中（称为后处理epilogue），并通过平移sp指针消去调用者的栈。编译器还应该小心地把一些只需要临时存储计算结果的数据存储到临时寄存器中，因为在函数调用后这些数据都很可能会丢失。

### 3.4 流水线优化

我们以上没有讨论处理器每条指令需要多长时间才能执行。单圈处理器的缺点是每个钟周期都只能执行一条指令，每个钟周期的长度不一样。如果优化使每个钟周期可以执行多条语句的话，我们就需要多圈处理器，即多个钟周期执行一条指令，比如每个钟周期只执行RISC-V中五个步骤中的一个，这样能确保每个钟周期长度基本相同。但这样每指令执行的圈数(CPI)就会远大于1，会导致处理器性能浪费。流水线是一种常见的用来优化多圈处理器执行的设计思路。

流水线优化的意思是，当指令1走到第2步时，第1步对应的处理器部分也没有闲着，开始处理指令2。当指令1走到第3步时，指令2走到第2步，指令3走到第1步。这样，每个钟周期处理器的每个部分都没有闲着，一下子就会把CPI拉回到1左右，大大加快指令的执行速度。

RISC-V处理器可以用五级流水线实现，每级流水恰好是我们在3.2节中介绍的5个步骤。我们在每一条跨越分区边界的电线上布置一个钟表上边出发的寄存器。*当钟表触发时，寄存器的值被更新，新的电平信号逐渐传到下一级电路中执行计算，却由于钟表没有触发而无法写入下一个寄存器。*这样我们就实现了把计算结果控制在每一级电路当中的效果。这样就缩短了每一钟周期执行的电路长度，从而缩短了钟周期，实现了电路各部分的高效利用，且基本上没有耽误指令的执行。

但流水线优化有显然的危险之处。在一族指令中一个*依赖*(dependency)于另一个的情况下，前一指令未完成后一指令就要获得某些前一指令还未来得及修改的数据，就会导致危险(hazard)。流水线优化主要有3种危险：结构危险、数据危险、控制危险。数据危险是指前一指令寄存器还未写入临时变量的寄存器（第5步）后一指令就要使用该临时变量的值（第2步）。可以让后一指令等待前一指令执行完再继续(stalling)，但这样效率较低。也可以让前一指令计算完就把未能来得及存到寄存器的临时变量转交给后一指令(forwarding)，这样通过让控制电路更复杂，能效率更高地解决数据危险。控制危险是指在第5步还未确定下一步需执行哪个指令时后一指令就已经出发了。这种危险可以通过等待前一指令执行完成，或者预测下一指令可能是什么来实现。分支预测器就是为了实现这个功能的。分支预测器的设计需要简单准确，可以通过哈希指令编号，记录处理器运行到某指令时是否选择跳步，以此来预测分支。结构危险是指并行造成的对处理器资源的争夺，一个例子是写入寄存器文件与读取寄存器文件冲突。这时我们可以通过在钟表下降边写入，在钟表上升边读取来解决这个结构危险，另一个例子是第1步对指令内存的访问与第4步对数据内存的访问冲突。这时可以采取分置两个内存（缓存）来化解冲突。

### 3.5 其他架构简介

指令集架构一般是指汇编语言语法构成的一套硬件体系。一般我们可以把指令集架构分为RISC(reduced instruction set computer)和CISC(complex instruction set computer)。CISC是最早出现的指令集架构，而x86是CISC的代表。x86有大于一千条指令，指令不等长，也需要不同的钟周期实现，同一个操作可能能由很多种指令集实现。最重要的是，x86语言允许编程者直接在内存上做运算。因此x86是非load-store架构。x86的语言更加简洁，因为一个复杂的操作可能写一行指令就可以实现，编译器也能有更多空间优化，但这也就意味着其处理器更加复杂。

与CISC不同的是，RISC有较少的指令，指令一般都是4个字节（等长），同一操作可以选择的指令有限，一般一个操作在一个钟周期内就能完成。最重要的是内存中的数据必须装载到寄存器文件中才能实现运算，运算完还必须写一条指令存储回去——语言不允许直接对内存中的数据运算。RISC指令的特点是简洁高效，优化更常用的情形，适用于更节能的场合。RISC-V是一种RISC，而在智能手机芯片中常用的ARM也是一种RISC语言。

### 3.6 编译以后

程序语言是人与计算机硬件交互的工具。不同的语言采用了不同的交互方式。以C为例，编译器(compiler)先通过词法、句法分析、类型检查、转为汇编语言等，把程序从源代码(.c或.h或.cpp等等)编译成汇编文件(.s)。前面我们所讲的调用惯例等等，就是编译器在编译高级语言函数调用代码时所要遵守的规则。编译时编译器是不知道#include<...>和extern等符号或文件是否存在的，也不知道自己中没有找到定义的符号是否真正存在。为此它会编制一张符号表，把自己找不到的符号都写在那里，把符号表附在汇编码的末尾。

在程序被编译成汇编语言后，汇编器(assembler)会把编译文件转化成二进制的对象文件(.o)，并把一些汇编语言中为方便实现造出的label、alias指令等转化成标准指令。对象文件中存储的内容包括宏观数据（本文件大小、位置等）、指令、静态数据、debug所用的行号、代码地址等、符号表等。通过objdump等工具可以对对象文件和可执行文件等反汇编，从而把二进制文件翻译成汇编码。

连接器(linker)将所有对象文件要调用的头文件结合起来，把符号表中未决的符号全部找到，把所有对象文件的地址空间合并并确保其无冲突，重设整个程序的进入点，生成一个只包含一块代码和一块全局变量的可执行文件(windows中为.exe，linux中无后缀）。某些连接器还负责把程序中用到的静态库全部复制粘贴到可执行文件中，包括C的标准库，这些连接器称为静态连接器。灵活一些的连接器并不会把标准库也附在可执行文件中，而是让可执行文件执行时跳到系统中已经存储好的标准库中执行，这样可以提高标准库代码的使用效率，这些连接器称为动态连接器。

当可执行程序需执行时，装载器(loader)会将可执行文件载入内存，跳到第一条指令，开始执行该程序的进程。启动装载器是操作系统负责的任务。

## 第4章 内存

现代电脑的内存常常被设计成等级形式，这是由于一般越快的内存越贵，因此越少，越慢的内存越便宜，因此越多。最快的寄存器直接放在处理器中间，以便处理器高效存储；次快的SRAM总是放在距离处理器较近的位置，作为缓存；慢一些的DRAM放在处理器之外，作为电脑的主内存（DRAM就是俗称的内存条）；磁盘、固态硬盘作为永久存储，速度非常慢（需要几百万个钟周期才能访问），因此距离处理器最远（一般放在电脑的另一端），大小也最大，为了访问永久存储必须借助操作系统。然而，通过有效设计内存的结构，并且利用人们访问内存的规律去预测可能访问的内存，我们可以制造拥有大量且快速内存的幻象，还可以让不同程序都有独享同一块大内存的幻象。这就是缓存和虚拟内存的原理。

### 4.1 缓存

如果每次内存调用都去主内存，甚至永久存储读写的话，那么程序的运行就会难以想象的慢——去芯片以外的任何地方（包括主内存）都要至少100个钟周期，去主内存更是要几百万个钟周期。事实上，大量的内存访问是有规律的：程序偏好访问已经访问过的内存和靠近已访问过内存的内存。为了加快内存访问，有必要利用时间和空间局域化原理，在一次内存访问时就把芯片外的部分其他数据拉回芯片，单独存储在芯片上一块区域（比如SRAM），这块区域就是缓存(cache)。也就是说，缓存存储的是它预测程序最可能访问的内存。如果程序要求访问的数据恰好在缓存中，那么我们就避免了那100个钟周期的走出芯片拉取内存的惩罚，这样就大大提升了内存访问性能。

缓存最重要的性能指标是击中率。如果程序想访问某内存地址，且该内存地址的内容恰在缓存上，这称为缓存击中(hit)，否则称为缓存丢失(miss)。击中的内存访问占总访问的比重称为击中率，1减去击中率称为丢失率。

每个程序运行开始时，缓存都是空的，这时难免会有很多丢失，这种miss称为cold miss。这时电路需要从内存中拉取数据到缓存。为了利用局域化原理，设计电路时一般会拉取程序需要的那个字节和其附近的数个字节，存储在缓存里，这个数据单位称为缓存块。缓存块中的字节都是相邻的，一般可以用offset表示一个缓存块中每个单独的字节。每个缓存块上存储时除了需要存储拉取的数据，还要存储标签位（标记这个缓存在内存中的地址）和校验码等，以说明此缓存块在内存中的地址及缓存块是否有效。直接映射型和集合映射型缓存块上为了加速查找，还会把地址中的几个比特作为访问缓存的索引。因此一个内存地址就会被缓存分隔成索引位、标签位和offset位。

缓存有三种：直接映射型缓存、完全结合型缓存，和集合结合型缓存。*直接映射型缓存*的每一个索引中只存储一个缓存块。此种缓存查找的方式是先按照索引找到对应的缓存块，再查看标签位是否与所要求的标签位相同，如果不相同则miss，如果相同则hit，再按照offset位找到数据。直接映射型缓存的优点是速度快，但缺点也很多。有时最近明明访问过某地址，却因其对应的缓存被另一地址刷新而无法访问该缓存，这种现象称为冲突(conflict)，会导致conflict miss。

为了减少冲突，缓存应增加其*结合性*。结合性的含义是同一个索引位中不止有一个缓存块。当索引位中第一个缓存块的空间被其他数据占据时，缓存还可以把要求的数据存到同一个索引位（称为缓存集, set，可以想成一行）的第二个缓存块中。每个集合中第i列的缓存块组成了结合型缓存的第i个way（列）。K-way*集合结合型缓存*把N个缓存块分成了N/K个缓存集，每个缓存集中有K个结合起来的缓存块。当K=1时，此缓存为直接映射型缓存，当K=N时，此缓存只有一个缓存集，没有必要安排索引位，称为*完全结合型缓存*。当缓存集存满时，为了继续存储需要弹出该集中某个缓存块，一般我们遵守LRU策略，即弹出最近最少使用的缓存块，为此每个缓存集都必须维护一个LRU指针，指向当丢失时需要弹出的缓存块地址。当然也可以采用其他策略，例如随机选择同一集合中一个缓存块弹出。

缓存的丢失率、判断是否击中时间、冲突率等指标性能一般不可兼得。增加结合性可以减少冲突，进而减少丢失率，但却会增加判断某缓存是否击中的时间。增加块大小可以覆盖更多相邻地址，却也会增加冲突。有的时候哪怕把缓存设计成完全结合型缓存都无法避免丢失，这种丢失称为capacity miss。增加缓存的容量（缓存块的总个数）可以减少丢失率（尤其是capacity miss），但也会增加判断击中时间。

为了最大限度地利用缓存，在设计电脑架构时可以把缓存也分成不同层。更接近寄存器文件的缓存层更快，结合性小，缓存块小，容量小。更远离寄存器文件的缓存层更慢，结合性高，缓存块大，容量大。

以上我们只讨论了读取内存时用缓存优化的问题。当我们要写入内存时，我们还需要考虑写入分配问题，即是否在缓存未击中时把内存块也拉到缓存中去，和更新内存问题，即是否在更新缓存时也更新内存。一般我们在写入缓存未击中时，也把内存块拉到缓存去，这称为write allocate policy。写入缓存时也写入对应的内存的策略称为write through policy，不写入内存，而等到该块被刷新时再写入内存的策略称为write back policy。遵守write back policy的缓存中每个块额外增加一个脏位，当脏位为1时代表此块曾经被写入，在此块被弹出时必须把整块写入内存。write back当频繁读取和写入某个数据时一般来说更快，但它每次写入都必须写入一整个缓存块，而且在多线程和分布式场合很难维持数据一致，因此write through有时也是合适的选择。

### 4.2 虚拟内存

如何在同一套硬件上（包括处理器和内存）同时运行多个程序（本笔记中与“进程”混用）？同一套内存硬件中，如何确定哪个内存地址是哪个程序的内存？如何确保不同程序的内存地址空间不冲突？如果一个程序需要的内存太多，以致于主内存不够用，如何让该程序有效使用永久存储（磁盘、闪存）？硬件中的内存管理单元(MMU)可以给每个程序一个假象，即每个程序都占有全部的内存地址空间。每个程序中读取的内存地址都是虚拟地址，而事实上与该地址对应的物理地址与它的虚拟地址并不相同，内存管理单元维护一张从真正内存到每个程序的虚拟内存的地址表就可以完成给程序分配内存的任务。

为了方便内存虚拟化，我们把内存按页分配，每一内存页一般有4kB内存。一内存页最多时候只被一个进程占用。内存管理单元这时只需要负责胡乱地分配各页就可以了（为了防止某些不安全的进程，这种分配应该越随机越好！）。进程们只有自己内存的虚拟页码，为了访问自己的内存，它们需要拿着虚拟页码到内存管理单元，内存管理单元通过在处理器上的页码表寄存器(PTBR)找到内存中存储的地址表，在该进程的地址表（页码表）中找到其对应的物理页码，再把物理页码的那批内存调过来，就实现了虚拟内存机制。

虚拟内存可以提高内存存储效率，方便内存的合理分配。虚拟内存还可以把永久存储的存储空间搬过来，形成内存比实际临时内存还大的假象。但虚拟内存也有缺点，主要缺点是存储页码表的花销很大，每个进程都需要为所有内存地址(4GB)中每个可能的页都分配一个存储页码表的空间。一张页码表对于4GB内存来说可能需要4MB。当几百个进程同时运行时，光页码表就快要把临时内存耗光了。解决方法是优化页码表的数据结构，让页码表成树状存储，不为进程没有使用的页码分配空间，这样能省下很大的空间。有时候进程要求扩大其使用的内存，或者要求访问永久存储，这时进程要求的页就可能无法在页码表中找到其主内存中对应的物理页码，这种现象称为page fault。由于page fault一般意味着程序需要访问新的内存（很可能在永久存储上），page fault一般由操作系统通过系统调用（5.1节会讲到，细节在操作系统1.2节中）处理。

找寻页码是否在页码表中存在（或者说判断是否有page fault）是非常耗时的工作。可以利用缓存，即翻译侧视缓冲器（translation lookaside buffer, TLB），来提升找寻页码过程的性能。为了找寻页码，程序需在TLB中先看看页码表中有没有要求的页码。如果有，则返回其物理页码，程序紧接着再拿着物理页码访问缓存，如果缓存击中则皆大欢喜，程序喜滋滋地拿着数据回去了。如果缓存丢失也不要紧，程序访问主内存一定能找到数据。如果TLB中没有它要求的页码，程序就需要通过硬件或操作系统的页码表丢失处理器，缓慢地在主内存中找到自己的物理页码，把自己的物理页码存到TLB中。如果在页码表中还没搜到自己的物理页码，那就是发生了page fault，这时内存管理单元会进行系统调用，更慢地从永久存储中读取需要的页码和内存，直到操作系统通过中断宣告读取完毕。关于虚拟内存、TLB和page fault的更多内容，请看操作系统笔记1.2节。

### 4.3 永久存储

永久存储的发展非常快，从十几年前以磁带为基础介质到现在以大数据中心、云计算为存储中心，云成为了现代数据的载体。

传统磁盘在不断地被优化以减小寻址时间，通过优化找寻数据的顺序来减少磁头的移动距离。甚至微机也被用于加速磁盘寻址。现在也有通过存储多个冗余磁盘以容错和加速的存储方式。关于如何利用冗余磁盘高效存储，以及这些技术如何组成现代的大数据中心，请看操作系统笔记3.1节。

## 第5章 操作系统、并发与输入输出

本章我们从硬件的角度讨论对操作系统的支持，并指出硬件在操作系统处理异常、中断和输入输出时的重要作用。本章还会讨论并发编程，及硬件与软件应如何结合才能提升并行编程的效率。

### 5.1 系统调用、异常和中断

并发编程中经常需要多个程序（即**进程**,process）共用一套硬件。操作系统是负责让多个进程各司其职不乱来的一个进程，因此操作系统有管理进程的特权。为了确保操作系统的特权，在硬件上应设置一个进程状态寄存器(process status register)，其中有一个CPU模式比特，而只有属于操作系统进程的模式比特才是1，这样就实现了系统资源的安全分配。

在电脑启动时，硬件会首先把包含操作系统代码的永久存储部分导入内存，将CPU模式比特设为1，将PC寄存器设为指定寄存器；然后操作系统从指定寄存器开始执行，启动其他设备、MMU、计时器等，从永久存储导入程序，启动页码表等，将CPU模式比特设置为0，PC设置为其他程序的起始点，开始执行其他程序。

当然进程需要输入输出、网络连接、访问永久存储（处理page fault）等，这些都是超出其权限的操作。这时它们可以通过系统调用机制，让操作系统帮忙实现输入输出、网络连接等功能。如果其要求过分，比如说要求占用太多内存的话，操作系统可直接把它们关闭。这样就保证了程序运行安全。

系统调用是一种特殊的函数调用，在RISC-V中称为ECALL。在系统调用前，编译器需要指明需执行哪种系统调用，在RISC-V汇编语言中可以通过设置函数参数a7来实现。在进程的虚拟地址空间中，有一半的内存空间(>=0x80000000的空间)是系统专用空间，这些内存空间平时是不允许访问的。当ECALL执行时，为保证安全，操作系统会通过硬件支持，以*原子化*的方式一次性执行以下操作：跳到进程中的某个固定地址（此地址会核对模式比特与该地址权限是否相符），保存原有的sp和PC到专属于此进程的核调用栈，把sp切换到核的sp（为防止内存泄漏），保存原有的模式比特，把CPU模式比特设置为1，把新PC设置成核系统调用处理器。在核中，系统调用处理器会保存调用者的寄存器，检查系统调用号，检查参数，调用相应的系统调用以完成操作，把结果存储在a0，恢复调用者寄存器，并借用硬件支持，通过“监督异常返回”(SRET)的方式，以*原子化*的方式一次性恢复用户的模式比特、sp和PC，恢复程序执行。

系统调用只是一种进程运行中的异常控制流。其他异常还有错误（包括软件异常、page fault等）、中断（由硬件或计时器等触发的事件）、断电等不可抗力因素。硬件需要提供异常处理的支持。在遇到中断时，硬件应让流水线之前的指令执行完成，清空流水线之后指令的效果，以*原子化*的方式一次性执行以下事项：在SEPC寄存器中存储异常执行的指令，在SCAUSE寄存器中存储造成异常的原因，保存必要的寄存器，保存并切换模式，切换到操作系统内核中的中断或异常处理器。操作系统中断和异常处理器应保存所有寄存器，检查原因，执行对中断原因的检查或处理（必要时终止程序，甚至关机）。当操作系统完成异常处理后，操作系统会恢复所有寄存器，并原子化地执行SRET，让原进程正常执行。

### 5.2 并行和多核编程

#### 指令级并行

一味地追求提高钟周期以增强性能并没有意义，因为那样会导致芯片的能量功率大到难以忍受。3.4节中的流水线其实已经是一种并行(parallelism)——指令间并行——即命令A和命令B可以在不同阶段同时执行。为了增加处理器效率，指令级并行也很常见。

指令级并行一般指多重发射(issue)，即一个处理器上有多条流水线，但它们只分享一个缓存。对多重发射的处理器来说，一般有一重发射只进行算术和分支运算，而另一重发射执行内存访问运算。为了避免危险，编译器应该把同类指令合并到一起推到发射，形成超长指令词，这种编译器负责调度指令执行到哪个发射的方式称为静态调度。编译器必须做大量的优化以使静态调度效果更好，包括循环展开、函数内联、基本块重组等（在4120笔记中有介绍），但终归有一些依赖无法在编译时发现，比如内存别名等。

动态多重发射的处理器会自己处理多重发射带来的危险，自己选择在哪一重发射里执行哪个指令（如SuperScalar处理器）。性能更优的处理器更进一步，实现了动态调度，即打乱顺序执行指令(OoO)，遇到危险时重命名寄存器，猜测分支预测的结果，猜错则回滚等。在侦查危险上，硬件拥有比编译器更多的信息（比如可以知道内存重名）因此动态调度也有其优点。

#### 线程级并行

指令级并行也有很多缺点，最重要的就是没有让编程者注意到硬件的并行性。通过线程级并行，编程者也可以通过自己的控制提升硬件使用率。线程级并行的的基本概念是**线程**(thread)。一个进程可以包含多个线程，它们共享指令、数据（堆）、文件和进程虚拟地址空间，但每个线程有各自的寄存器和调用栈。当某线程由于缓存丢失或系统调用需要停止执行时，操作系统可以执行线程切换，把另一个线程调度到处理器中执行，这样处理器的流水线就能塞得更满。

#### 多核硬件与缓存自恰

除了一个处理器上可以有多个流水线，一个电脑中也可以有多个处理器（核），所有处理器都有自己的L1和L2缓存，但它们共同分享一个L3缓存。多套硬件给了编程者很大的施展空间，不过要用好硬件并行并不容易。根据Amdahl's Law，硬件并行只能缩短程序可并行部分的运行时间，并不能缩短程序必须串行部分的运行时间。因此一味多发射多核并不能解决所有的性能问题。

从硬件角度，多核并行最大的问题是各个内核的缓存不自恰(coherent)。现代硬件的框架是共享内存多处理器(SMM)，多个核及其缓存以总线(bus)与内存、输入输出、其他硬件（如显卡）等连接，这就可能导致每个核中对同一个共享内存地址存储的数据并不相同。【注意内存一致性(consistency)指的是在不同核间指令执行顺序不一致，与缓存自恰不是一个概念。】

所谓自恰，是指同一个内存地址在所有缓存中一个时刻只能有一个值。MSI机制是一种实现缓存自恰的机制。它的实质是硬件上添加一个自恰控制器，侦听(snoop)对某个缓存地址中处理器的要求和总线的信息，并让这些信息触发有限状态机，更改缓存中数据的有效性。MSI机制的有限状态机共有3个态：M态（一人写）、S态（共享只读）、I态（有人写，本数据过期，禁止更改）。三个态之间相互转化，例如如果总线上传来某地址发生了“写入丢失”，则说明该地址即将被人写，MSI机制会把本缓存中那个数据的版本从S态改为I态。

缓存自恰问题引入了另两种丢失：upgrade miss，指对只读块写的时候需要触发MSI机制造成延迟；coherence miss，指在别的处理器写时自己无法读，必须触发MSI机制在总线上更新所有缓存的本地址数据才能读。注意到MSI机制是对缓存块标记MSI状态的，如果不同核没有频繁更新一个内存地址，却需要频繁更新同一个缓存块，那么共享内存没有实际分享该数据却会频繁触发丢失，这个现象称为虚假分享，需要避免。

#### 线程间同步

缓存自恰并不能解决所有并行编程中的问题，编程者还需多加小心：如果不小心把需要顺序执行（排他执行）的操作并行了，将会导致竞争执行等棘手的问题。只有到所有可能的调度都安全（称为线程同步synchronization），程序才能保证正确。

硬件对线程同步提供了多种支持，原子化读写地址是最主要的一种支持。RISC-V中使用了LR和SC(load reserved, store conditional)两个原子化语句。LR执行载入，并开始监视该地址。SC在从开始监视该地址以来没有任何进程或线程写入的时候写入，其余情况下报错。利用这两个语句，我们可以实现自旋互斥锁。当某程序希望执行重要片段时，它应该尝试通过SC得锁。如果无法得到，则会继续循环尝试得锁，直到其他程序退出，自己得锁。

在多线程程序设计时，我们必须恰当利用锁。读取和写入共享内存都必须加锁。一种要避免的情况是死锁，这要求我们必须按某个顺序加锁，即给锁优先级。另一个重要的机制是要求操作系统提供wait函数查看某个条件是否满足，只有当条件满足时才会尝试获得锁，否则会继续等待，这样既省去了死循环的资源浪费，又保证不会在尝试获得锁后条件又不满足了。

4410笔记中的第2章对并行和并发有更多的介绍，读写锁、条件变量、信号量、监视器等都是常见的保证并行安全的数据结构。

### 5.3 输入和输出

不同的输入输出设备效率不同，但与人交互的输入输出设备效率一般比处理器和内存的效率都低得多。为了不减慢硬件速度，从硬件上就应该把输入输出、读取内存等操作较慢的步骤分开管理，并与系统其他的高性能部分分离。总线在这个分离过程中起到了重要的作用。总线的参数有带宽、传输速度，以及是否允许并发等。处理器与内存之间的总线速度快，距离短，带宽大，而输入输出的总线则更长、更慢、更窄。由于不同输入输出方式的差别很大，总线机制可能不太高效，点对点的数据传输成为技术的新趋势。

如何让输入输出设备与程序交互呢？程序可通过系统调用启动输入输出。为了传输输入输出的数据，操作系统可指定某些内存地址的访问被重定向到输入输出设备的API，这个API是由命令寄存器、状态寄存器和数据寄存器组成的，而这些内存地址只有操作系统能够访问。这样输入输出数据的写入和读取也可以利用原有的虚拟内存处理方法，即重用缓存和虚拟内存等这些机制。这种机制称为直接内存访问输入输出(DMA)。DMA比起另一种机制PIO，即构造一个操作系统管理的软件程序，使得所有进程都通过这个程序与输入输出交互的机制更加高效。

输入输出设备在完成其任务后应该通过系统调用，向程序发送中断信号，而程序需要通过设置handler去处理这些不可预知的输入输出信息。一般来说这种方式比起每个钟周期都检查有没有输入输出（polling）来更高效。
